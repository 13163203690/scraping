{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实例1：京东商品页面的爬取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://item.jd.com/100004770249.html\" \n",
    "try:\n",
    "    kv = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.150 Safari/537.36'}\n",
    "    r = requests.get(url,headers=kv) \n",
    "    r.raise_for_status()\n",
    "    r.encoding = r.apparent_encoding \n",
    "    print(r.text[:1000])\n",
    "except:\n",
    "    print(\"爬取失败\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实例2：亚马逊商品页面的爬取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://www.amazon.cn/dp/B01MYH8A99\" \n",
    "try:\n",
    "    kv = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.150 Safari/537.36'}\n",
    "    r = requests.get(url,headers=kv) \n",
    "    r.raise_for_status()\n",
    "    r.encoding = r.apparent_encoding \n",
    "    print(r.content.decode('utf-8'))\n",
    "    \n",
    "except:\n",
    "    print(\"爬取失败\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实例 3百度360搜索关键词提交 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://www.baidu.com/s\" \n",
    "try:\n",
    "    kv = {'wd':\"python\"}\n",
    "    #kv = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.150 Safari/537.36'}\n",
    "    r = requests.get(url,params=kv) \n",
    "    r.raise_for_status()\n",
    "    print(r.request.url)\n",
    "    print(len(r.text))\n",
    "    \n",
    "except:\n",
    "    print(\"爬取失败\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实例4：网络图片的爬取和存储"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "url = 'https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE4wwtv?ver=1428'\n",
    "path = \"E://pystudy//1.jpg\"\n",
    "if not os.path.exists(path):\n",
    "    kv = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.150 Safari/537.36'}\n",
    "    r = requests.get(url, headers=kv)\n",
    "    r.raise_for_status()\n",
    "    with open(path, 'wb') as f:\n",
    "        f.write(r.content)  # r.content表示返回内容的二进制形式，\n",
    "        f.close()  # 图片是以二进制形式存储的\n",
    "        print(\"文件保存成功\")\n",
    "else:\n",
    "    print(\"文件已存在\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = 'https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE4wwtv?ver=1428'\n",
    "r = requests.get(url)\n",
    "with open('E://pystudy//2.jpg', 'wb') as f:\n",
    "    f.write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实例5：IP地址归属地的自动查询"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = \"http://m.ip138.com/ip.asp?ip=\"\n",
    "r = requests.get(url + '202.204.80.112')\n",
    "r.raise_for_status()\n",
    "r.encoding = r.apparent_encoding\n",
    "print(r.text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import bs4\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.150 Safari/537.36'}\n",
    "url='https://www.shanghairanking.cn/api/pub/v1/bcur?bcur_type=11&year=2021'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHTMLText(url):\n",
    "    '''从网络上获取大学排名网页内容'''\n",
    "    try:\n",
    "        r = requests.get(url, headers=headers,timeout=40) \n",
    "        # #如果状态不是200，就会引发HTTPError异常\n",
    "        r.raise_for_status()\n",
    "        r.encoding = r.apparent_encoding\n",
    "        return r.text\n",
    "    except:\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillUnivList(text, num):\n",
    "    # response = requests.get(url, timeout=40)\n",
    "    # text = response.text\n",
    "    data = json.loads(text)\n",
    "    content = data['data']['rankings']\n",
    "    ulist = []\n",
    "    for i in range(num):\n",
    "        index = content[i]['rankOverall']\n",
    "        name = content[i]['univNameCn']\n",
    "        score = content[i]['score']\n",
    "        category = content[i]['univCategory']\n",
    "        ulist.append([index, name, score, category])\n",
    "    return ulist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printUnivList(ulist):\n",
    "    # 打印前 num 名的大学\n",
    "    #tplt =\"{0:^10}\\t{1:^10}\\t{2:^10}\\t{3:^10}\"\n",
    "    tplt = \"{0:^10}\\t{1:{3}^10}\\t{2:^10}\\t{4:^10}\"   # {1:{3}^10} 中的 {3} 代表取第三个参数\n",
    "    print(tplt.format(\"排名 \", \"学校名称\", \"总分\", chr(12288), \"类型\"))  # chr(12288) 代表中文空格\n",
    "    for i in range(100):\n",
    "        u = ulist[i]\n",
    "        # chr(12288) 代表中文空格\n",
    "        print(tplt.format(u[0], u[1], u[2], chr(12288), u[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    text=getHTMLText(url)\n",
    "    ulist=fillUnivList(text, 100)\n",
    "    printUnivList(ulist)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 淘宝商品信息定向爬虫\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.150 Safari/537.36'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_page(text):\n",
    "    title = re.findall(r'<div class=\"p-name.*?>.*?<em>(.*?)</em>.*?</div>', text, flags=re.DOTALL)\n",
    "    price = re.findall(r'<div class=\"p-price\">.*?<i>(.*?)</i>.*?</div>', text,flags=re.DOTALL)\n",
    "    herf=re.findall(r'<div class=\"p-name.*?>.*?<a.*?herf=\"(.*?)\">.*?</div>', text, flags=re.DOTALL)\n",
    "    print('title',title)\n",
    "    print(price)\n",
    "    print('#'*20)\n",
    "    print(herf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHTMLText(url):\n",
    "    '''从网络上获取大学排名网页内容'''\n",
    "    try:\n",
    "        r = requests.get(url, headers=headers,timeout=40) \n",
    "        # #如果状态不是200，就会引发HTTPError异常\n",
    "        r.raise_for_status()\n",
    "        r.encoding = r.apparent_encoding\n",
    "        return r.text\n",
    "    except:\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    keyword ='女装套装'\n",
    "    url='https://search.jd.com/Search?keyword='+keyword\n",
    "    print(url)\n",
    "    text=getHTMLText(url)\n",
    "    parse_page(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://search.jd.com/Search?keyword=女装套装\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
